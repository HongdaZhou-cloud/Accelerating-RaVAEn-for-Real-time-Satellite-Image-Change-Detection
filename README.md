# Accelerating RaVÆn for Real-time Satellite Image Change Detection

**Abstract**  
Data processing on satellites aids real-time identification of critical information  and preferential downlink. RaVÆn, a lightweight, unsupervised learning approach based on Variational Auto-Encoders, was proposed to detect changes in satellite images, thereby facilitating timely data downlink and analysis. However, there is a significant gap between the required processing time and the practical image update frequency generated by Earth observation satellites like Sentinel-2.

Because this real-time change detection task occurs on power-constrained satellites, we explore the use of Field-Programmable Gate Arrays (FPGAs) to achieve high computing speed. We use high-level synthesis (HLS) to structure the hardware task into six processing stages and optimize each stage to balance resource utilization and performance. An adaptive framework is developed to suggest the choice of parameters to optimize each stage for an effective HLS design that meets different practical requirements among the design space explored. 

Targeting a Kria KV260 board, our FPGA-based system processes non-overlapping images updated on Sentinel-2 in real-time, and achieves a 20x throughput improvement and 13x energy saving compared to a CPU-based implementation that uses the NEON extension. The framework reliably assesses HLS design choices within a few seconds. It makes full use of the available FPGA resources when maximum acceleration is required, and avoids over-acceleration to conserve power when faced with specific throughput targets. The outcome demonstrates the exceptional performance of an FPGA-based design for executing the RaVÆn algorithm, and the efficiency of our framework for implementing RaVÆn on different satellite platforms.

---

## File System
The project have two parts: one is the FPGA-based implementation and one is the software implementation.
### FPGA
This includes the FPGA-based implementation for the case study when we accelerate a design as much as possible for Sentinel-2 satellite mission on a Kria KV260 Vision AI Starter Kit.

The input is the images captured from Sentinel-2 with 12-bit pixel data.
#### PL
In this project, High-level Synthesis (HLS), is utilized for implementing PL circuits in FPGAs. We used Vitis HLS 2021.2 for accelerator IP and Vivado 2021.2 for block design and implementation.

"framework.ipynb" is the framework for the adaptive FPGA-based implementation. The user needs to capture the model parameters according to HLS synthesis results first before use it.
##### Run HLS project:
1. In HLS direction, make a direction called "encoder_m_axi";
2. Run "script.tcl" to create Solution 1, with command in: 
```bash
vitis_hls -f script.tcl
```
3. Open Solution 1 in Vitis HLS GUI.

NOTE: Because of the some inherent bugs in HLS (or limited computer memory), use code lines 151, 709\~753 and change data type of "mu_weights" as (ap_fixed <26,2>) for synthesis and implementation; lines 152, 755\~799 and change data type of "mu_weights" as (float) for C simulation in Vitis HLS.

#### PS 
This project uses the PYNQ framework to implement the software and control the PL part of the MPSOC. Follow the link: https://github.com/Xilinx/Kria-PYNQ to flash the SD card with PYNQ.

"encoder_ps.ipynb" is the code to run PS to control the PL part.

The pre-implemented PL part for the case study is in files "encoder.bit" and "encoder.hwh", upload them in Jupter notebook before running PS.

---
### Software
The code for the software implementation is in "RaVAEn_KV260.ipynb" file. 

"Single_scene_before" contains an image for historical latent vectors; "unprocessed_after2.tiff.npy" is the data in an image for present latent vectors.  

"model_vae.json" is the pre-trained parameters for RaVAEn processing 10-band images. If we need to test the performance of processing other numbers of bands, we can load random parameters.  

